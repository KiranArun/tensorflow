{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# My notebook for playing with tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from IPython import display\n",
    "import sklearn as skl\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### code to print 10 random integers from 1 to 10 all squared in tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16  1  9 49 64  4  4 16  1 16]\n"
     ]
    }
   ],
   "source": [
    "#make up some random data in a numpy array\n",
    "data = np.random.randint(1,10, size=10)\n",
    "\n",
    "#x is a constant with the values of data\n",
    "x = tf.constant(data)\n",
    "#y is a variable with the value x^2\n",
    "y = tf.Variable(x**2)\n",
    "\n",
    "#initialize all vairables is when it first runs the lines of the variable above\n",
    "model = tf.global_variables_initializer()\n",
    "\n",
    "#run session, session is needed as this is when it actually completes the commands\n",
    "with tf.Session() as sess:\n",
    "    #run the global variable initializer\n",
    "    sess.run(model)\n",
    "    #print y from in the session\n",
    "    print(sess.run(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### code for tensorflow loop where each loop $(x+1)^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "4\n",
      "9\n",
      "16\n",
      "25\n"
     ]
    }
   ],
   "source": [
    "#set up x and y as variables witt value 0\n",
    "x = tf.Variable(0)\n",
    "y = tf.Variable(0)\n",
    "\n",
    "#set model to initialize variables\n",
    "model = tf.global_variables_initializer()\n",
    "\n",
    "#run session\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    #run the global variables  initializer\n",
    "    sess.run(model)\n",
    "    \n",
    "    #loop 5 times within session\n",
    "    for i in range(5):\n",
    "    \n",
    "        #update values of x and y\n",
    "        x += 1\n",
    "        y = x**2\n",
    "        \n",
    "        #print y\n",
    "        print(sess.run(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tensorfow loop where it creates random value and prints out  ann updated average of the random digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "416\n",
      "403\n",
      "310\n",
      "476\n",
      "523\n"
     ]
    }
   ],
   "source": [
    "#set up tensorflow variables to 0\n",
    "num = tf.Variable(0)\n",
    "ave = tf.Variable(0)\n",
    "tot = tf.Variable(0)\n",
    "\n",
    "#set model to initialize variables\n",
    "model = tf.global_variables_initializer()\n",
    "\n",
    "#run session\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    #initialize variables\n",
    "    sess.run(model)\n",
    "    \n",
    "    #loop 5 times\n",
    "    for i in range(5):\n",
    "        \n",
    "        #calculate and  set variables values\n",
    "        num += 1\n",
    "        ran = np.random.randint(1000)\n",
    "        tot = tot+ran\n",
    "        average = tot/num\n",
    "        \n",
    "        #print average\n",
    "        print(sess.run(average))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### uses tensorboard and logs the data in /home/logdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n"
     ]
    }
   ],
   "source": [
    "#define variables\n",
    "x = tf.constant(35)\n",
    "y = tf.Variable(x + 5)\n",
    "\n",
    "#variable initializer\n",
    "model =  tf.global_variables_initializer()\n",
    "\n",
    "#run session\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    #using tensorboard,writing to directory /home/logdir\n",
    "    merged = tf.summary.merge_all()\n",
    "    writer = tf.summary.FileWriter(\"/home/logdir\", sess.graph)\n",
    "\n",
    "    #run the model and print output\n",
    "    sess.run(model)\n",
    "    print(sess.run(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### example of using placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.  4.  9.]\n"
     ]
    }
   ],
   "source": [
    "#x is a place holder, 3 is the number of values ofthe  placeholder\n",
    "x = tf.placeholder(\"float\", 3)\n",
    "square = x ** 2\n",
    "\n",
    "#run session\n",
    "with tf.Session() as sess:\n",
    "    #result equals y with x being given the values of 1, 2 and 3\n",
    "    result = sess.run(square, feed_dict={x: [1, 2, 3]})\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interactive Sessions\n",
    "\n",
    "if there is already a session running it will use that but if it is a fresh kernal it will need this session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.16674513  0.07046588  2.68909485]\n",
      " [-2.95719171 -1.41545754  0.27649172]\n",
      " [ 1.4410921  -1.41243649 -0.35895217]\n",
      " [-0.21562654  0.86923509 -2.00050152]\n",
      " [ 0.26396882 -0.76427279  0.55739216]\n",
      " [ 2.5576366  -1.40562566 -1.61091455]\n",
      " [ 1.09796962  0.32380876 -1.58085821]\n",
      " [ 0.27559044 -1.7667023  -0.29377744]\n",
      " [-0.41036859 -1.05423438  0.85175779]\n",
      " [-0.98196339  1.0526539  -1.11529439]]\n"
     ]
    }
   ],
   "source": [
    "# make interactive session\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "# create variablesor constants\n",
    "# variables will need initializer like:\n",
    "# X.initializer.run()\n",
    "X = tf.constant(np.eye(10))\n",
    "Y = tf.constant(np.random.randn(10, 3))\n",
    "\n",
    "Z = tf.matmul(X, Y)\n",
    "print Z.eval()\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### messing about with different tensors and matrices addition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 2  4  6]\n",
      "  [ 8 10 12]]\n",
      "\n",
      " [[ 2  4  6]\n",
      "  [ 8 10 12]]]\n"
     ]
    }
   ],
   "source": [
    "a = tf.constant([[[1,2,3], [4,5,6]],[[1,2,3], [4,5,6]]])\n",
    "b = tf.constant([[[1,2,3], [4,5,6]],[[1,2,3], [4,5,6]]])\n",
    "sum = a + b\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(sum))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3 4]\n",
      " [2 3 4 5]]\n",
      "[[1 2 3]\n",
      " [4 5 6]\n",
      " [7 8 9]\n",
      " [2 4 5]]\n",
      "[[38 52 62]\n",
      " [52 71 85]]\n"
     ]
    }
   ],
   "source": [
    "a = tf.constant([[1,2,3,4], [2,3,4,5]])\n",
    "b = tf.constant([[1,2,3], [4,5,6], [7,8,9], [2,4,5]])\n",
    "mul = tf.matmul(a, b)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print a.eval()\n",
    "    print b.eval()\n",
    "    print(sess.run(mul))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### example of using very simple linear training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W: [ 2.99928832] b: [-1.99505734] loss: 7.67941e-05\n"
     ]
    }
   ],
   "source": [
    "W = tf.Variable([0.0], tf.float32)\n",
    "b = tf.Variable([0.0], tf.float32)\n",
    "x = tf.placeholder(tf.float32)\n",
    "y = tf.placeholder(tf.float32)\n",
    "\n",
    "learning_rate =  0.001\n",
    "x_train = np.linspace(0,10,11).astype(np.float32)\n",
    "y_train = x_train * 3.0 -2\n",
    "\n",
    "output = W*x+b\n",
    "squared_deltas = tf.square(output - y)\n",
    "loss = tf.reduce_sum(squared_deltas)\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "train = optimizer.minimize(loss)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for i in range(1000):\n",
    "        sess.run(train, {x:x_train, y:y_train})\n",
    "        \n",
    "        \n",
    "    curr_W, curr_b, curr_loss  = sess.run([W, b, loss], {x:x_train, y:y_train})\n",
    "    print(\"W: %s b: %s loss: %s\"%(curr_W, curr_b, curr_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W: [ 4.99987221] b: [-8.99911213] loss: 2.47714e-06\n"
     ]
    }
   ],
   "source": [
    "W = tf.Variable([0.0], tf.float32)\n",
    "b = tf.Variable([0.0], tf.float32)\n",
    "\n",
    "learning_rate =  0.0015\n",
    "x = np.linspace(0,10,11).astype(np.float32)\n",
    "y = x_train *5.0 - 9.0\n",
    "\n",
    "output = x*W+b\n",
    "squared_deltas = tf.square(output - y)\n",
    "loss = tf.reduce_sum(squared_deltas)\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "train = optimizer.minimize(loss)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for i in range(1000):\n",
    "        sess.run(train)\n",
    "        \n",
    "    curr_W, curr_b, curr_loss  = sess.run([W, b, loss])\n",
    "    print(\"W: %s b: %s loss: %s\"%(curr_W, curr_b, curr_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## This is a linear regression example which tensorflow made in their notebook 2.\n",
    "## I added my own comment so i understand it better. It is a  very simple script just showing the basic bits like gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb5480fee10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y = [ 0.82714355] x + [ 0.48153478]\n"
     ]
    }
   ],
   "source": [
    "# number of of points on the graph\n",
    "num_examples = 100\n",
    "\n",
    "# make arrays x and y with random noise added to them\n",
    "# with the x values from 0-6 and y values form 4-16 without noise\n",
    "X = np.array([np.linspace(0, 6, num_examples), np.linspace(0, 6, num_examples)])\n",
    "X += np.random.randn(2, num_examples)\n",
    "x, y = X\n",
    "\n",
    "# create array with shape 2 by a with first value equaling 1\n",
    "# these are basically the m and c from y = mx+ c\n",
    "x_with_bias = np.array([(1., a) for a in x]).astype(np.float32)\n",
    "\n",
    "# create loss tracker and set  parameters\n",
    "losses = []\n",
    "training_steps = 100\n",
    "learning_rate = 0.001\n",
    "\n",
    "# start session\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    # set tensorflow values using variable from before\n",
    "    # input is the x values to be put into the equation\n",
    "    # target is the y values in the equation\n",
    "    input = tf.constant(x_with_bias)\n",
    "    target = tf.constant(np.transpose([y]).astype(np.float32))\n",
    "    \n",
    "    # weights are set random at first in a 1 by 2 array\n",
    "    weights = tf.Variable(tf.random_normal([2, 1], 0, 0.1))\n",
    "\n",
    "    # initialize variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    # yhat is the output of function mx + c by multiplying the matrices input(1's and x values) and weights(m and c)\n",
    "    yhat = tf.matmul(input, weights)\n",
    "    # find error by subtracting target from output of equation\n",
    "    yerror = tf.subtract(yhat, target)\n",
    "    # to minimize L2 loss. This is the sum of all the squared errors.\n",
    "    # it effects larger errors a lot more than small errors\n",
    "    loss = tf.nn.l2_loss(yerror)\n",
    "  \n",
    "    # using gradient descent to update weights, weights += grads * learning_rate\n",
    "    # using the partial derivative of the loss to decrease the error\n",
    "    # by finding which direction to move the weights\n",
    "    update_weights = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)\n",
    "  \n",
    "    # loop number of training steps and run update weights\n",
    "    for _ in range(training_steps):\n",
    "        update_weights.run()\n",
    "        # append to losses array\n",
    "        losses.append(loss.eval())\n",
    "\n",
    "    # get final values from the session\n",
    "    betas = weights.eval()\n",
    "    yhat = yhat.eval()\n",
    "\n",
    "# plot the random points\n",
    "plt.scatter(x, y)\n",
    "# plot the random x values with the new y values\n",
    "plt.scatter(x, np.transpose(yhat)[0], c=\"g\")\n",
    "# set line x range and plot the line\n",
    "line_x_range = (-2, 8)\n",
    "plt.plot(line_x_range, [betas[0] + a * betas[1] for a in line_x_range], \"g\", alpha=0.6)\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "print 'y =',betas[1],'x +',betas[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
